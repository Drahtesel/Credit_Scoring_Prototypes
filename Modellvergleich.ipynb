{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drahtesel/Credit_Scoring_Prototypes/blob/main/Modellvergleich.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0n_1-x6ANafK"
      },
      "outputs": [],
      "source": [
        "!pip install lime\n",
        "import lime\n",
        "import lime.lime_tabular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c347a5ec"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Finales Training und Vergleich der Vorhersagequalität\n",
        "# ============================================================\n",
        "# Dieses Notebook:\n",
        "# Lädt die vorbereiteten Daten (X, y)\n",
        "# (Die Daten wurde im Rahmen des Notebook \"Datenvorbereitung\" vorbereitet)\n",
        "#\n",
        "# Initialisiert die folgenden Modelle unter Nutzung der optimalen Hyperparameter:\n",
        "#       - Logistische Regression\n",
        "#       - Random Forest\n",
        "#       - XGBoost\n",
        "#       - Neuronales Netz (MLP)\n",
        "# (Die Hyperparameter wurden innerhalb des Notebooks \"Optimierung\" identifiziert)\n",
        "#\n",
        "## Trainiert die Prototypen\n",
        "# Führt Cross-Validation durch (10-Fold)\n",
        "#\n",
        "# Wendet die folgenden Methoden an, die die Erklärbarkeit erhöhen:\n",
        "#       - SHAP\n",
        "#       - LIME\n",
        "# ============================================================\n",
        "\n",
        "\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TunedThresholdClassifierCV, StratifiedKFold, train_test_split, cross_val_score, cross_validate\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    make_scorer, accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, precision_recall_curve, roc_curve,\n",
        "    average_precision_score, log_loss\n",
        ")\n",
        "\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt_6NoWFS8xl"
      },
      "outputs": [],
      "source": [
        "# --- Datenverzeichnis ----------------------------------------\n",
        "data_dir = \"/content/drive/MyDrive/Thesis/Daten/DataPreprocess/german_credit_prepared\"\n",
        "\n",
        "# Speichern von Grafiken\n",
        "output_dir = '/content/drive/MyDrive/Thesis/Grafiken'\n",
        "\n",
        "# --- Daten laden ---------------------------------------------\n",
        "X = pd.read_csv(f\"{data_dir}/X_prepared_FS_15.csv\")\n",
        "y = pd.read_csv(f\"{data_dir}/y_labels_FS_15.csv\")\n",
        "\n",
        "if isinstance(y, pd.DataFrame):\n",
        "   y = y.iloc[:, 0]\n",
        "\n",
        "models = [\"LR\", \"RF\", \"XGB\", \"NN\"]\n",
        "\n",
        "# --- Färbung für Diagramme --- #\n",
        "colors = {\n",
        "    \"LR\": \"tab:blue\",\n",
        "    \"RF\": \"tab:green\",\n",
        "    \"XGB\": \"tab:red\",\n",
        "    \"NN\": \"tab:purple\"\n",
        "}\n",
        "\n",
        "# --- Train/Test Split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.34, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- Define class_weight_map ---\n",
        "class_weight_map = {0: 1, 1: 5}\n",
        "\n",
        "print(\"Daten geladen:\")\n",
        "print(f\"X-Shape: {X.shape}, y-Shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7C55bvasEOWH"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# --- Hilfsfunktionen ---\n",
        "# ============================================================\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "def mean_ci_curve(list_of_curves):\n",
        "    x_new = np.linspace(0, 1, 200)\n",
        "\n",
        "    y_interp = []\n",
        "    for x, y in list_of_curves:\n",
        "        y_new = np.interp(x_new, x, y)\n",
        "        y_interp.append(y_new)\n",
        "\n",
        "    y_interp = np.array(y_interp)\n",
        "\n",
        "    mean = y_interp.mean(axis=0)\n",
        "    std  = y_interp.std(axis=0)\n",
        "\n",
        "    ci_low  = mean - 1.96 * std / np.sqrt(len(list_of_curves))\n",
        "    ci_high = mean + 1.96 * std / np.sqrt(len(list_of_curves))\n",
        "\n",
        "    return x_new, mean, ci_low, ci_high\n",
        "\n",
        "\n",
        "#Kostenmatrix: FN = 5, FP = 1\n",
        "def cost_based_score(y_true, y_pred):\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))  # False Negatives\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))  # False Positives\n",
        "    cost = 5 * fn + 1 * fp\n",
        "    return -cost\n",
        "\n",
        "cost_scorer = make_scorer(cost_based_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZcpmcWi3qWm"
      },
      "outputs": [],
      "source": [
        "# Modelle werden initialisiert, dabei wird für jedes Modell die besten Hyperparameter\n",
        "# mitgegeben, welche innerhalb der Bayesian Optimization gefunden wurden.\n",
        "\n",
        "models = {}\n",
        "\n",
        "# ============================================================\n",
        "# Logistic Regression  (Best)\n",
        "# penalty_num = 1.931899373004111 -> l2\n",
        "# C = 0.1546198805628967 ~ 0.1546\n",
        "# max_iter = 808.8759013578529 ~ 809\n",
        "# ============================================================\n",
        "\n",
        "models[\"LR\"] = LogisticRegression(\n",
        "    penalty=\"l2\",\n",
        "    C=0.1546,\n",
        "    solver=\"liblinear\",\n",
        "    max_iter=809,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Random Forest  (Best)\n",
        "# n_estimators = 157.55183698544803 ~ 158\n",
        "# max_depth = 16.902047828739427 ~ 17\n",
        "# min_samples_split = 4.006214142616203 ~ 4\n",
        "# min_samples_leaf = 4.195301787774554 ~ 4\n",
        "# max_features = 12.685751882611433 ~ 13\n",
        "# criterion_num = 2.0 -> entropy\n",
        "# ============================================================\n",
        "\n",
        "models[\"RF\"] = RandomForestClassifier(\n",
        "    n_estimators=158,\n",
        "    max_depth=17,\n",
        "    min_samples_split=4,\n",
        "    min_samples_leaf=4,\n",
        "    max_features=13,\n",
        "    criterion=\"entropy\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# XGBoost  (Best)\n",
        "# n_estimators = 84.39892848538969 ~ 84\n",
        "# max_depth = 3.735142261085808 ~ 4\n",
        "# learning_rate = 0.1408404244699492 ~ 0.1408\n",
        "# subsample = 0.8335741651642962 ~ 0.8336\n",
        "# colsample_bytree = 0.609140992220957 ~ 0.6091\n",
        "# gamma = 0.7162505127777915 ~ 0.7163\n",
        "# min_child_weight = 1.9004156542307995 ~ 1.9\n",
        "# reg_alpha = 2.830371351065982 ~ 2.8304\n",
        "# reg_lambda = 3.2940020164375814 ~ 3.2940\n",
        "# ============================================================\n",
        "\n",
        "models[\"XGB\"] = XGBClassifier(\n",
        "    n_estimators=84,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.1408,\n",
        "    subsample=0.8336,\n",
        "    colsample_bytree=0.6091,\n",
        "    gamma=0.7163,\n",
        "    min_child_weight=1.9,\n",
        "    reg_alpha=2.8304,\n",
        "    reg_lambda=3.2940,\n",
        "    eval_metric=\"logloss\",\n",
        "    objective=\"binary:logistic\",\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Neural Network  (Best)\n",
        "# n_layers = 2.169357893245109  ~ 2\n",
        "# n_neurons = 26.057360338427756 ~ 26\n",
        "# alpha = 0.01\n",
        "# learning_rate_init = 0.0060571179633747 ~ 0.006057\n",
        "# learning_rate_idx = 2.0 -> adaptive\n",
        "# batch_size = 46.16082092287091 ~ 46\n",
        "# max_iter = 699.8370647892802 ~ 700\n",
        "# activation_num = 2.0 -> relu\n",
        "# ============================================================\n",
        "\n",
        "hidden_layers = tuple([26] * 2)\n",
        "\n",
        "models[\"NN\"] = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"nn\", MLPClassifier(\n",
        "        hidden_layer_sizes=hidden_layers,\n",
        "        alpha=0.01,\n",
        "        learning_rate_init=0.006057,\n",
        "        batch_size=46,\n",
        "        max_iter=700,\n",
        "        early_stopping=True,\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        learning_rate=\"adaptive\",\n",
        "        random_state=42\n",
        "    ))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a2c1e92"
      },
      "outputs": [],
      "source": [
        "# Konfiguration der Kreuzvalidierung\n",
        "N_RUNS = 10  # mehrere Durchgänge für höhere Ergebnisstabilität\n",
        "N_SPLITS = 10 # Folds je Kreuzvalidierung\n",
        "\n",
        "# Berücksichtigung der asymmetrischen Kosten\n",
        "# for name, model in models.items():\n",
        "#     if not isinstance(model, TunedThresholdClassifierCV):\n",
        "#         models[name] = TunedThresholdClassifierCV(\n",
        "#             estimator=model,\n",
        "#             scoring=cost_scorer,\n",
        "#             cv=N_SPLITS\n",
        "#         )\n",
        "\n",
        "results_all_folds = []\n",
        "roc_data = {m: [] for m in models.keys()}\n",
        "\n",
        "print(f\"Starting {N_RUNS}x {N_SPLITS}-Fold Cross-Validation...\")\n",
        "\n",
        "for run_idx in range(N_RUNS):\n",
        "    print(f\"--- Run {run_idx+1}/{N_RUNS} ---\")\n",
        "\n",
        "    # Stratifizierte Kreuzvalidierung für robustere Ergebnisse\n",
        "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=run_idx)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        # Random State um Zufälligkeiten zwischen den Runs zuzulassen\n",
        "        if hasattr(model, \"random_state\"):\n",
        "            model.random_state = None\n",
        "\n",
        "        if hasattr(model, \"steps\") and hasattr(model.steps[-1][1], \"random_state\"):\n",
        "            model.steps[-1][1].random_state = None\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
        "            X_train_fold, X_test_fold = X.iloc[train_idx], X.iloc[test_idx]\n",
        "            y_train_fold, y_test_fold = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "            # Training der Modelle\n",
        "            model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "            # Get predicted probabilities and classes for the test data of the current fold\n",
        "            y_probs_fold = model.predict_proba(X_test_fold)[:, 1]\n",
        "            y_preds_fold = model.predict(X_test_fold)\n",
        "\n",
        "            # Metriken berechnen\n",
        "            auc_fold = roc_auc_score(y_test_fold, y_probs_fold)\n",
        "            logl_fold = log_loss(y_test_fold, y_probs_fold)\n",
        "            acc_fold = accuracy_score(y_test_fold, y_preds_fold)\n",
        "            f1_fold = f1_score(y_test_fold, y_preds_fold)\n",
        "            fn = np.sum((y_test_fold == 1) & (y_preds_fold == 0))\n",
        "            fp = np.sum((y_test_fold == 0) & (y_preds_fold == 1))\n",
        "            expected_cost_fold = 5 * fn + 1 * fp\n",
        "\n",
        "            results_all_folds.append({\n",
        "                \"Run\": run_idx,\n",
        "                \"Fold\": fold_idx,\n",
        "                \"Model\": name,\n",
        "                \"AUC\": auc_fold,\n",
        "                \"LogLoss\": logl_fold,\n",
        "                \"Accuracy\": acc_fold,\n",
        "                \"ExpectedCost\": expected_cost_fold\n",
        "            })\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(y_test_fold, y_probs_fold)\n",
        "            roc_data[name].append((fpr, tpr))\n",
        "\n",
        "print(\"\\nCross-Validation complete. Generating plots and summary.\")\n",
        "\n",
        "# --- Visualisierung der ROC Kurve mit 95% Konfidenzintervallen ---\n",
        "plt.figure(figsize=(10,6))\n",
        "for name in models.keys():\n",
        "    x, mean, lo, hi = mean_ci_curve(roc_data[name])\n",
        "    plt.plot(x, mean, label=name)\n",
        "    plt.fill_between(x, lo, hi, alpha=0.2)\n",
        "plt.plot([0,1],[0,1],\"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig(f\"{output_dir}/ROC_Curves.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- Zusammenfassung der Metriken über alle Folds und Runs ---\n",
        "df_results_all_folds = pd.DataFrame(results_all_folds)\n",
        "\n",
        "summary_metrics = df_results_all_folds.groupby(\"Model\").agg(\n",
        "    AUC_mean = (\"AUC\", \"mean\"),\n",
        "    AUC_std   = (\"AUC\", \"std\"),\n",
        "    LogLoss_mean = (\"LogLoss\", \"mean\"),\n",
        "    LogLoss_std   = (\"LogLoss\", \"std\"),\n",
        "    Acc_mean = (\"Accuracy\", \"mean\"),\n",
        "    Acc_std  = (\"Accuracy\", \"std\"),\n",
        "    ExpCost_mean = (\"ExpectedCost\", \"mean\"),\n",
        "    ExpCost_std  = (\"ExpectedCost\", \"std\")\n",
        ")\n",
        "\n",
        "# Formatierung der Ergebnisse\n",
        "summary_formatted = pd.DataFrame({\n",
        "    \"AUC\":      summary_metrics[\"AUC_mean\"].round(4).astype(str) + \" ± \" + summary_metrics[\"AUC_std\"].round(4).astype(str),\n",
        "    \"Accuracy\": summary_metrics[\"Acc_mean\"].round(4).astype(str) + \" ± \" + summary_metrics[\"Acc_std\"].round(4).astype(str),\n",
        "    \"LogLoss\":  summary_metrics[\"LogLoss_mean\"].round(4).astype(str) + \" ± \" + summary_metrics[\"LogLoss_std\"].round(4).astype(str),\n",
        "    \"Expected Cost\": summary_metrics[\"ExpCost_mean\"].round(1).astype(str) + \" ± \" + summary_metrics[\"ExpCost_std\"].round(1).astype(str)\n",
        "})\n",
        "\n",
        "summary_formatted['AUC_numeric'] = summary_metrics['AUC_mean'].round(4)\n",
        "summary_formatted = summary_formatted.sort_values(by='AUC_numeric', ascending=False).drop(columns='AUC_numeric')\n",
        "\n",
        "display(summary_formatted)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "717c9917"
      },
      "source": [
        "# @title Intrinsische Erklärbarkeit der Logistischen Regression\n",
        "lr_model = models[\"LR\"]\n",
        "\n",
        "# Überprüfen, dass das Model bereits trainiert ist\n",
        "if not hasattr(lr_model, 'coef_'):\n",
        "    print(\"Logistic Regression model not yet trained. Training now...\")\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    print(\"Model trained.\")\n",
        "\n",
        "coefficients = lr_model.coef_[0]\n",
        "feature_names = X_train.columns\n",
        "\n",
        "coef_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients\n",
        "})\n",
        "\n",
        "coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
        "coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
        "\n",
        "display(coef_df.head(15))\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Coefficient', y='Feature', data=coef_df.head(15),\n",
        "            palette=['red' if x < 0 else 'blue' for x in coef_df.head(15)['Coefficient']])\n",
        "plt.xlabel('Koeffizientenwert')\n",
        "plt.ylabel('Merkmal')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{output_dir}/LR_Coefficients.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "95qqBGVltnhv"
      },
      "outputs": [],
      "source": [
        "# @title SHAP\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def run_shap_analysis_and_plot(models_dict, X_train_data, X_test_data, title_suffix, include_checking_account_prefix=True, top_n_features=15):\n",
        "\n",
        "    prefixes = [\n",
        "        'credit_history',\n",
        "        'checking_account',\n",
        "        'purpose',\n",
        "        'savings_account',\n",
        "        'employment',\n",
        "        'personal_status',\n",
        "        'other_debtors',\n",
        "        'property',\n",
        "        'housing',\n",
        "        'job',\n",
        "        'telephone',\n",
        "        'foreign_worker',\n",
        "        'other_installment_plans'\n",
        "    ]\n",
        "\n",
        "    # Merkmale aggregieren, welche durch OHE getrennt wurden\n",
        "    def get_original_feature_name(col_name):\n",
        "        for prefix in prefixes:\n",
        "            if col_name.startswith(f'{prefix}_'):\n",
        "                return prefix\n",
        "        return col_name\n",
        "\n",
        "    print(f\"\\n=== SHAP Analysis{title_suffix} ===\")\n",
        "\n",
        "    for name, model in models_dict.items():\n",
        "        print(f\"\\n--- SHAP for {name}{title_suffix} ---\")\n",
        "\n",
        "        if isinstance(X_train_data, np.ndarray):\n",
        "            X_train_data_processed = pd.DataFrame(X_train_data, columns=X_train.columns)\n",
        "        else:\n",
        "            X_train_data_processed = X_train_data\n",
        "\n",
        "        if isinstance(X_test_data, np.ndarray):\n",
        "            X_test_data_processed = pd.DataFrame(X_test_data, columns=X_test.columns if name not in [\"LR\", \"NN\"] else X_train_data_processed.columns)\n",
        "        else:\n",
        "            X_test_data_processed = X_test_data\n",
        "\n",
        "        if name == \"LR\":\n",
        "            explainer_X_train_float = X_train_data_processed.astype(float)\n",
        "            explainer_X_test_float = X_test_data_processed.astype(float)\n",
        "            explainer = shap.LinearExplainer(model, explainer_X_train_float)\n",
        "            shap_values = explainer.shap_values(explainer_X_test_float)\n",
        "            X_plot_data = X_test_data_processed\n",
        "\n",
        "        elif name == \"RF\" or name == \"XGB\":\n",
        "            explainer = shap.TreeExplainer(model)\n",
        "            shap_values = explainer.shap_values(X_test_data_processed)\n",
        "            X_plot_data = X_test_data_processed\n",
        "\n",
        "        else:\n",
        "            def nn_predict_proba(X):\n",
        "                return model.predict_proba(X.astype(float))\n",
        "\n",
        "            background_data_for_explainer = shap.sample(X_train_data_processed, 100).astype(float)\n",
        "            explainer = shap.KernelExplainer(\n",
        "                nn_predict_proba,\n",
        "                background_data_for_explainer,\n",
        "            )\n",
        "            X_test_for_explanation = X_test_data_processed.iloc[:100].astype(float)\n",
        "            shap_values = explainer.shap_values(X_test_for_explanation)\n",
        "            X_plot_data = X_test_data_processed.iloc[:100]\n",
        "\n",
        "        # Extract SHAP values for the positive class\n",
        "        if isinstance(shap_values, list):\n",
        "            shap_values_for_plotting = shap_values[1]\n",
        "        elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
        "            shap_values_for_plotting = shap_values[:, :, 1]\n",
        "        else:\n",
        "            shap_values_for_plotting = shap_values\n",
        "\n",
        "        # Calculate mean absolute SHAP values for individual features\n",
        "        mean_abs_shap_values = np.abs(shap_values_for_plotting).mean(0)\n",
        "\n",
        "        feature_names_plot = X_plot_data.columns.tolist() if hasattr(X_plot_data, 'columns') else [f'Feature {i}' for i in range(X_plot_data.shape[1])]\n",
        "\n",
        "        # Aggregate SHAP values by original conceptual feature name\n",
        "        aggregated_shap_values = {}\n",
        "        for i, feature_name_ind in enumerate(feature_names_plot):\n",
        "            original_feature = get_original_feature_name(feature_name_ind)\n",
        "            if original_feature not in aggregated_shap_values:\n",
        "                aggregated_shap_values[original_feature] = 0\n",
        "            aggregated_shap_values[original_feature] += mean_abs_shap_values[i]\n",
        "\n",
        "        # Create a Series from aggregated values\n",
        "        shap_importance_aggregated = pd.Series(aggregated_shap_values)\n",
        "\n",
        "        # Sort and select top N features for plotting\n",
        "        shap_importance_aggregated = shap_importance_aggregated.sort_values(ascending=False).head(top_n_features)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap_importance_aggregated.plot(kind='barh')\n",
        "        plt.xlabel('Aggregierter mittlerer absoluter SHAP-Wert')\n",
        "        plt.ylabel('Feature')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/SHAP_{name}{title_suffix}.png\")\n",
        "        plt.show()\n",
        "\n",
        "# --- Call the consolidated function for original models ---\n",
        "run_shap_analysis_and_plot(models, X_train, X_test, title_suffix=' (Original Models)', include_checking_account_prefix=True, top_n_features=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d56258b"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbd0478b"
      },
      "outputs": [],
      "source": [
        "# @title LIME\n",
        "# Liste an Merkmalen für LIME\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "# Konvertieren von DataFrames in NumPy Arrays für den LIME explainer\n",
        "X_train_np = X_train.values\n",
        "X_test_np = X_test.values\n",
        "\n",
        "# Anzahl an Erklärungen\n",
        "num_explanations = 3\n",
        "example_indices = [0, 1, 2]\n",
        "print(\"\\n=== LIME Explanations ===\")\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Model: {name} ---\")\n",
        "\n",
        "    if name == \"NN\":\n",
        "        def predict_proba_nn_pipeline(X_raw):\n",
        "            return model.predict_proba(X_raw)\n",
        "\n",
        "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "            training_data=X_train_np,\n",
        "            feature_names=feature_names,\n",
        "            class_names=[\"Good Credit\", \"Bad Credit\"],\n",
        "            mode='classification'\n",
        "        )\n",
        "        predict_fn = predict_proba_nn_pipeline\n",
        "\n",
        "    else:\n",
        "        explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "            training_data=X_train_np,\n",
        "            feature_names=feature_names,\n",
        "            class_names=[\"Good Credit\", \"Bad Credit\"],\n",
        "            mode='classification'\n",
        "        )\n",
        "        predict_fn = model.predict_proba\n",
        "\n",
        "    for idx in example_indices:\n",
        "        instance_to_explain = X_test_np[idx]\n",
        "        true_label = y_test.iloc[idx] # Use .iloc for Series\n",
        "\n",
        "        predicted_proba = predict_fn(instance_to_explain.reshape(1, -1))[0]\n",
        "        predicted_label = 1 if predicted_proba[1] > 0.5 else 0\n",
        "\n",
        "        explanation = explainer.explain_instance(\n",
        "            data_row=instance_to_explain,\n",
        "            predict_fn=predict_fn,\n",
        "            num_features=10  # Anzahl an Merkmale, die betrachtet werden\n",
        "        )\n",
        "\n",
        "        print(f\"\\nInstance {idx} (True Label: {true_label}, Predicted Label: {predicted_label})\")\n",
        "        explanation.as_pyplot_figure()\n",
        "        plt.gca().set_title('')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{output_dir}/LIME_{name}_Instance_{idx}.png\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_Zp70u_1xgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lYBfDp7WaKK-Xlo0N4DoY6XaXFGdg8ga",
      "authorship_tag": "ABX9TyMjnEKv3l9Sjbw+5U6ioaL9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}